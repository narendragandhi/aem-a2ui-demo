# Environment Configuration Example
# Copy this file to .env and modify as needed

# ===========================================
# General Settings
# ===========================================
LOG_LEVEL=INFO

# ===========================================
# Python Agent Settings
# ===========================================
PYTHON_AGENT_PORT=10002
PYTHON_ADVANCED_PORT=10004

# ===========================================
# Java Agent Settings
# ===========================================
JAVA_AGENT_PORT=10003
SPRING_PROFILES_ACTIVE=default
JAVA_OPTS=-Xmx512m

# ===========================================
# Client Settings
# ===========================================
VITE_PYTHON_AGENT_URL=http://localhost:10002
VITE_JAVA_AGENT_URL=http://localhost:10003

# ===========================================
# AEM Integration (Optional)
# ===========================================
# AEM_HOST=http://localhost:4502
# AEM_USER=admin
# AEM_PASSWORD=admin

# ===========================================
# AI/LLM Integration
# ===========================================
# Enable AI-powered content generation
AI_ENABLED=false

# LLM Provider: openai, anthropic, or ollama
LLM_PROVIDER=ollama

# -------------------------------------------
# Option 1: OpenAI (Cloud)
# -------------------------------------------
# OPENAI_API_KEY=sk-your-openai-api-key
# OPENAI_MODEL=gpt-4o-mini

# -------------------------------------------
# Option 2: Anthropic (Cloud)
# -------------------------------------------
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key
# ANTHROPIC_MODEL=claude-3-haiku-20240307

# -------------------------------------------
# Option 3: Ollama (Local - No API Key Needed)
# -------------------------------------------
# Install: https://ollama.ai
# Run: ollama run llama3.2
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
