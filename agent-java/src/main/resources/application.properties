# Server Configuration
server.port=10003

# Application Name
spring.application.name=aem-a2ui-agent

# JSON Output
spring.jackson.serialization.indent-output=true

# Embabel Agent Configuration
embabel.agent.platform.name=aem-content-assistant
embabel.agent.platform.description=AI-powered content assistant for AEM authoring
embabel.agent.platform.scanning.annotation=true

# LLM Provider Configuration (uses OPENAI_API_KEY or ANTHROPIC_API_KEY env vars)
embabel.agent.platform.models.openai.max-attempts=3
embabel.agent.platform.models.openai.backoff-millis=1000
embabel.agent.platform.models.anthropic.max-attempts=3
embabel.agent.platform.models.anthropic.backoff-millis=1000

# Autonomy Settings
embabel.agent.platform.autonomy.agent-confidence-cut-off=0.6
embabel.agent.platform.autonomy.goal-confidence-cut-off=0.6

# LLM Operations
embabel.llm-operations.prompts.generate-examples-by-default=true

# Feature flags for AI mode
aem.agent.ai.enabled=${AI_ENABLED:false}
aem.agent.ai.fallback-to-templates=true

# LLM Provider Selection: openai, anthropic, or ollama
aem.agent.llm.provider=${LLM_PROVIDER:ollama}

# OpenAI Configuration
aem.agent.llm.openai.base-url=https://api.openai.com/v1
aem.agent.llm.openai.model=${OPENAI_MODEL:gpt-4o-mini}

# Anthropic Configuration
aem.agent.llm.anthropic.base-url=https://api.anthropic.com/v1
aem.agent.llm.anthropic.model=${ANTHROPIC_MODEL:claude-3-haiku-20240307}

# Ollama Configuration (local LLM - no API key required)
aem.agent.llm.ollama.base-url=${OLLAMA_BASE_URL:http://localhost:11434}
aem.agent.llm.ollama.model=${OLLAMA_MODEL:llama3.2}

# ========================================
# Security Configuration
# ========================================

# CORS settings (comma-separated list of allowed origins)
# For production, set to specific domains: https://your-domain.com
cors.allowed-origins=${CORS_ALLOWED_ORIGINS:http://localhost:5173,http://localhost:3000}
cors.max-age=3600
cors.allow-credentials=true

# Strict mode - fails startup if insecure settings detected
security.strict-mode=${SECURITY_STRICT_MODE:false}

# API Key authentication (recommended for production)
security.api-key.enabled=${SECURITY_API_KEY_ENABLED:false}
security.api-key.value=${SECURITY_API_KEY:}

# HSTS (enable when serving over HTTPS)
security.hsts.enabled=${SECURITY_HSTS_ENABLED:false}
security.hsts.max-age=31536000

# Rate limiting
security.rate-limit.enabled=true
security.rate-limit.requests-per-minute=${RATE_LIMIT_RPM:60}

# ========================================
# AEM SDK Integration Configuration
# ========================================

# Enable/disable real AEM integration (false = use mock mode)
aem.enabled=${AEM_ENABLED:true}

# AEM Author instance URL
aem.author-url=${AEM_AUTHOR_URL:http://localhost:4502}

# AEM Publish instance URL
aem.publish-url=${AEM_PUBLISH_URL:http://localhost:4503}

# AEM credentials (use environment variables in production)
# WARNING: Never commit real credentials to version control
aem.username=${AEM_USERNAME:admin}
aem.password=${AEM_PASSWORD:admin}

# Content paths
aem.content-root=${AEM_CONTENT_ROOT:/content/aem-demo}
aem.dam-root=${AEM_DAM_ROOT:/content/dam/aem-demo}
aem.workflow-models-path=/var/workflow/models

# HTTP client configuration
aem.connect-timeout=${AEM_CONNECT_TIMEOUT:5000}
aem.read-timeout=${AEM_READ_TIMEOUT:30000}
aem.max-retries=3
aem.retry-delay-millis=1000

# ========================================
# Logging Configuration
# ========================================
logging.level.com.example.aema2ui=INFO
logging.level.com.example.aema2ui.config.SecurityConfig=INFO
